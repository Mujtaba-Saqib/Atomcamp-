{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561cc7f7-cdbd-40f5-90e7-a5b559b33d79",
   "metadata": {},
   "source": [
    "# CV - Object Detection\n",
    "## Model: YOLO | Dataset: Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c81d88-5711-4824-a1e2-83c10b9bc996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob as glob\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f5c00-3004-496e-a941-9f9f226c6619",
   "metadata": {},
   "source": [
    "# 1. Train on Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af305b-1176-425e-825d-a1fb1e8949a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43207fa8-b328-40f7-86f5-e68f983fb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/mnt/c/Users/AI/Documents/sandbox/ac_dl_11/odc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fc6523-ff01-4da6-abdb-10c9ca213c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8673910-0a02-40da-8bad-7f9dddb2ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.161 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.160 ðŸš€ Python-3.10.18 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/mnt/c/Users/AI/Documents/sandbox/ac_dl_11/odc/dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 1.4Â±0.1 ms, read: 61.7Â±18.0 MB/s, size: 246.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Users/AI/Documents/sandbox/ac_dl_11/odc/dataset/train/labels.cache... 561 images, 0 backgrounds, \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.7Â±0.2 ms, read: 53.5Â±20.4 MB/s, size: 305.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/AI/Documents/sandbox/ac_dl_11/odc/dataset/val/labels.cache... 20 images, 0 backgrounds, 0 cor\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10       1.2G      1.007      2.872      1.498          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:08<00:00,  8.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.771      0.458      0.641      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      1.27G      1.233      2.561      1.689          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 10.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.281      0.583      0.389      0.219\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      1.28G      1.184      2.256      1.662          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 10.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.804      0.686      0.798      0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10       1.3G      1.241      2.072      1.682          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 11.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.599      0.686      0.664      0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      1.31G      1.158      1.856      1.603          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 11.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.446      0.671      0.582      0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      1.33G      1.069      1.619      1.524          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 11.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.814      0.792      0.832      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      1.34G      1.041      1.544      1.469          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 11.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.934      0.667      0.789      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      1.36G      1.005      1.435       1.45          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 11.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.852      0.721       0.91       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      1.37G     0.8793      1.302      1.341          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 11.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.841      0.708      0.847      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      1.37G     0.8539      1.229      1.318          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 11.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.914      0.625      0.865      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.160 ðŸš€ Python-3.10.18 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.914      0.625      0.865      0.594\n",
      "Speed: 0.3ms preprocess, 1.6ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=os.path.join(ROOT_DIR, 'dataset', 'data.yaml'), batch=8, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3bfa1d-1d73-4c69-a324-1d80b25e236f",
   "metadata": {},
   "source": [
    "## 1.1 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c4df46-668d-4da1-a7f4-b2add79028f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.160 ðŸš€ Python-3.10.18 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.2Â±0.1 ms, read: 109.6Â±57.0 MB/s, size: 413.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/AI/Documents/sandbox/ac_dl_11/odc/dataset/val/labels.cache... 20 images, 0 backgrounds, 0 cor\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20         24      0.852      0.625      0.852      0.572\n",
      "Speed: 3.9ms preprocess, 28.6ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f732231a-adf5-4915-92e1-649a5606cd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5719967657652494\n",
      "0.8516542045651212\n",
      "0.5761294695004672\n",
      "[      0.572]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.box.map)\n",
    "print(metrics.box.map50)\n",
    "print(metrics.box.map75)\n",
    "print(metrics.box.maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62109d8c-7c5f-4985-8eb0-6ce977a3cc0a",
   "metadata": {},
   "source": [
    "## 1.2 Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc80ac20-9504-4a8c-bf64-ea3ab72ba2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = sorted(glob.glob(os.path.join(ROOT_DIR, 'dataset', 'test', 'images') + '/*.jpg'))\n",
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c14ff66d-26f2-4a62-b816-ae71a69555c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 handgun, 3.8ms\n",
      "1: 640x640 1 handgun, 3.8ms\n",
      "2: 640x640 (no detections), 3.8ms\n",
      "3: 640x640 1 handgun, 3.8ms\n",
      "4: 640x640 2 handguns, 3.8ms\n",
      "5: 640x640 1 handgun, 3.8ms\n",
      "6: 640x640 1 handgun, 3.8ms\n",
      "7: 640x640 (no detections), 3.8ms\n",
      "8: 640x640 2 handguns, 3.8ms\n",
      "9: 640x640 1 handgun, 3.8ms\n",
      "10: 640x640 1 handgun, 3.8ms\n",
      "11: 640x640 1 handgun, 3.8ms\n",
      "12: 640x640 (no detections), 3.8ms\n",
      "13: 640x640 1 handgun, 3.8ms\n",
      "14: 640x640 1 handgun, 3.8ms\n",
      "15: 640x640 (no detections), 3.8ms\n",
      "16: 640x640 (no detections), 3.8ms\n",
      "17: 640x640 1 handgun, 3.8ms\n",
      "18: 640x640 1 handgun, 3.8ms\n",
      "19: 640x640 1 handgun, 3.8ms\n",
      "20: 640x640 1 handgun, 3.8ms\n",
      "21: 640x640 (no detections), 3.8ms\n",
      "22: 640x640 1 handgun, 3.8ms\n",
      "23: 640x640 (no detections), 3.8ms\n",
      "24: 640x640 1 handgun, 3.8ms\n",
      "25: 640x640 1 handgun, 3.8ms\n",
      "26: 640x640 1 handgun, 3.8ms\n",
      "27: 640x640 1 handgun, 3.8ms\n",
      "28: 640x640 1 handgun, 3.8ms\n",
      "29: 640x640 2 handguns, 3.8ms\n",
      "30: 640x640 1 handgun, 3.8ms\n",
      "31: 640x640 1 handgun, 3.8ms\n",
      "32: 640x640 1 handgun, 3.8ms\n",
      "33: 640x640 1 handgun, 3.8ms\n",
      "34: 640x640 1 handgun, 3.8ms\n",
      "35: 640x640 1 handgun, 3.8ms\n",
      "36: 640x640 1 handgun, 3.8ms\n",
      "37: 640x640 1 handgun, 3.8ms\n",
      "38: 640x640 1 handgun, 3.8ms\n",
      "39: 640x640 1 handgun, 3.8ms\n",
      "40: 640x640 1 handgun, 3.8ms\n",
      "41: 640x640 2 handguns, 3.8ms\n",
      "42: 640x640 1 handgun, 3.8ms\n",
      "43: 640x640 1 handgun, 3.8ms\n",
      "44: 640x640 1 handgun, 3.8ms\n",
      "45: 640x640 1 handgun, 3.8ms\n",
      "46: 640x640 (no detections), 3.8ms\n",
      "47: 640x640 (no detections), 3.8ms\n",
      "48: 640x640 1 handgun, 3.8ms\n",
      "49: 640x640 1 handgun, 3.8ms\n",
      "50: 640x640 1 handgun, 3.8ms\n",
      "51: 640x640 1 handgun, 3.8ms\n",
      "52: 640x640 1 handgun, 3.8ms\n",
      "53: 640x640 1 handgun, 3.8ms\n",
      "54: 640x640 (no detections), 3.8ms\n",
      "55: 640x640 3 handguns, 3.8ms\n",
      "56: 640x640 1 handgun, 3.8ms\n",
      "57: 640x640 1 handgun, 3.8ms\n",
      "58: 640x640 1 handgun, 3.8ms\n",
      "59: 640x640 1 handgun, 3.8ms\n",
      "60: 640x640 1 handgun, 3.8ms\n",
      "61: 640x640 1 handgun, 3.8ms\n",
      "62: 640x640 (no detections), 3.8ms\n",
      "63: 640x640 1 handgun, 3.8ms\n",
      "64: 640x640 1 handgun, 3.8ms\n",
      "65: 640x640 1 handgun, 3.8ms\n",
      "66: 640x640 2 handguns, 3.8ms\n",
      "67: 640x640 1 handgun, 3.8ms\n",
      "68: 640x640 1 handgun, 3.8ms\n",
      "69: 640x640 1 handgun, 3.8ms\n",
      "70: 640x640 1 handgun, 3.8ms\n",
      "71: 640x640 1 handgun, 3.8ms\n",
      "72: 640x640 1 handgun, 3.8ms\n",
      "73: 640x640 1 handgun, 3.8ms\n",
      "74: 640x640 1 handgun, 3.8ms\n",
      "Speed: 3.8ms preprocess, 3.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(test_images, save=True, imgsz=640, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5697ee-3b4a-4380-a38d-4f02049f7420",
   "metadata": {},
   "source": [
    "## 1.3 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f27634-ea16-4379-8432-6122f1ec4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = YOLO(os.path.join(ROOT_DIR, 'runs', 'detect', 'train', 'weights', 'best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc84a8-188e-4ea9-84ea-0f260954c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.160 ðŸš€ Python-3.10.18 torch-2.7.1+cu126 CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "ðŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel CPUs. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/mnt/c/Users/AI/Documents/sandbox/ac_dl_11/odc/runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.56', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n"
     ]
    }
   ],
   "source": [
    "model_best.export(format=\"onnx\", dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301ecb5-2f62-4183-aeb1-63fe93c0a8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2516b-f76f-420d-beb0-6bcc2c6e882e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
